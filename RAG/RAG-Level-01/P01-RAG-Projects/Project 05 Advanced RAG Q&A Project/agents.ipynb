{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Advanced RAG Q&A Project With Multiple Data Sources With Langchain"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T02:48:12.597830Z",
     "start_time": "2025-11-12T02:48:12.593731Z"
    }
   },
   "source": [
    "from langchain_community.tools import WikipediaQueryRun \n",
    "from langchain_community.utilities import WikipediaAPIWrapper"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T02:48:12.637466Z",
     "start_time": "2025-11-12T02:48:12.622340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "# ËÆæÁΩÆhttpÁöÑ‰ª£ÁêÜÂíå‰∏ç‰ª£ÁêÜÁöÑÂú∞ÂùÄ\n",
    "os.environ['HTTP_PROXY'] = \"http://127.0.0.1:7890\"\n",
    "os.environ['HTTPS_PROXY'] = \"http://127.0.0.1:7890\"\n",
    "os.environ['NO_PROXY'] = \"127.0.0.1,localhost\" #ollamaÁöÑÊú¨Âú∞ÊúçÂä°Âú∞ÂùÄ\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API wrapper\n",
    "- this is basically use to query answer from wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T02:48:12.780929Z",
     "start_time": "2025-11-12T02:48:12.678442Z"
    }
   },
   "source": [
    "api_wrapper=WikipediaAPIWrapper(top_k_results=1,doc_content_chars_max=200)\n",
    "wiki=WikipediaQueryRun(api_wrapper=api_wrapper)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T02:48:12.805152Z",
     "start_time": "2025-11-12T02:48:12.794665Z"
    }
   },
   "source": [
    "wiki.name"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T02:48:24.392064Z",
     "start_time": "2025-11-12T02:48:12.851653Z"
    }
   },
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T02:48:24.416845Z",
     "start_time": "2025-11-12T02:48:24.401210Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_BASE\"] = os.getenv(\"OPENAI_API_BASE\")\n",
    "os.environ['OPENAI_API_KEY']=os.getenv('OPENAI_API_KEY')"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T02:48:39.380634Z",
     "start_time": "2025-11-12T02:48:24.453344Z"
    }
   },
   "source": [
    "loader=WebBaseLoader('https://docs.smith.langchain.com/')\n",
    "docs=loader.load()\n",
    "documents=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200).split_documents(docs)"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T02:48:53.955463Z",
     "start_time": "2025-11-12T02:48:39.389106Z"
    }
   },
   "source": [
    "# ‰∏¥Êó∂Â¢ûÂä†‰ª£ÁêÜ\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# ‰∏¥Êó∂Â¢ûÂä†‰ª£ÁêÜ\n",
    "# os.environ['HTTP_PROXY'] = \"http://127.0.0.1:7890\"\n",
    "# os.environ['HTTPS_PROXY'] = \"http://127.0.0.1:7890\"\n",
    "\n",
    "model_name = \"BAAI/bge-large-zh-v1.5\"\n",
    "model_kwargs = {'device': 'cpu', \"trust_remote_code\":True}\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "hf_emb_model = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "# ÂéªÈô§Â¢ûÂä†‰ª£ÁêÜ\n",
    "# os.environ.pop('HTTP_PROXY')\n",
    "# os.environ.pop('HTTPS_PROXY')\n",
    "\n",
    "## creating vector DB\n",
    "vectordb=FAISS.from_documents(documents, hf_emb_model)\n",
    "retriever=vectordb.as_retriever()\n",
    "retriever"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x73e652399650>, search_kwargs={})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T02:48:53.993652Z",
     "start_time": "2025-11-12T02:48:53.963357Z"
    }
   },
   "source": [
    "from langchain_core.tools.retriever import create_retriever_tool\n",
    "retriever_tool=create_retriever_tool(retriever,\"langsmith_search\",\"Search for information about Langsmith. For any questions about LangSmith, youmust use this tool\")"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T02:48:54.019628Z",
     "start_time": "2025-11-12T02:48:54.015700Z"
    }
   },
   "source": [
    "retriever_tool.name"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'langsmith_search'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arxiv Tool"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T02:48:54.082406Z",
     "start_time": "2025-11-12T02:48:54.068409Z"
    }
   },
   "source": [
    "from langchain_community.utilities import ArxivAPIWrapper\n",
    "from langchain_community.tools import ArxivQueryRun\n"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T02:48:54.177021Z",
     "start_time": "2025-11-12T02:48:54.122958Z"
    }
   },
   "source": [
    "arxiv_wrapper=ArxivAPIWrapper(top_k_results=1, doc_content_chars_max=200)\n",
    "arxiv=ArxivQueryRun(arxiv_wrapper=arxiv_wrapper)\n",
    "arxiv.name"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arxiv'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine All Tools"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T02:48:54.203833Z",
     "start_time": "2025-11-12T02:48:54.199371Z"
    }
   },
   "source": [
    "tools=[wiki,arxiv,retriever_tool]"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T02:48:54.260918Z",
     "start_time": "2025-11-12T02:48:54.254516Z"
    }
   },
   "source": [
    "tools"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from '/home/chester/gitlab.chesterwang.com/ai_demo_4_interview/RAG/RAG-Level-01/P01-RAG-Projects/.venv/lib/python3.11/site-packages/wikipedia/__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=200)),\n",
       " ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=3, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=4000)),\n",
       " Tool(name='langsmith_search', description='Search for information about Langsmith. For any questions about LangSmith, youmust use this tool', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x73e65186d4e0>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x73e652399650>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x73e6504eed40>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x73e652399650>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents\n",
    "- The core idea of agents is to use a language model to choose a sequence of actions to take. In chains, a sequence of actions is hardcoded (in code). In agents, a language model is used as a reasoning engine to determine which actions to take and in which order.\n",
    "[Learn more](https://python.langchain.com/v0.1/docs/modules/agents/)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T02:48:54.504392Z",
     "start_time": "2025-11-12T02:48:54.309557Z"
    }
   },
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "# llm = ChatOpenAI(model=\"kimi-k2-turbo-preview\", temperature=0) # ‰ºöÈÅáÂà∞httpcoreÁöÑÈóÆÈ¢ò\n",
    "# from langchain_community.llms import Ollama,ChatOllama\n",
    "from langchain_ollama import ChatOllama\n",
    "# llm = Ollama(model=\"deepseek-r1:1.5b\",\n",
    "#     base_url=\"http://localhost:11434\"  # ÊòéÁ°ÆÊåáÂÆö Ollama ÊúçÂä°Âú∞ÂùÄ\n",
    "# )\n",
    "llm = ChatOllama(model=\"qwen3:0.6b\",\n",
    "    base_url=\"http://localhost:11434\"  # ÊòéÁ°ÆÊåáÂÆö Ollama ÊúçÂä°Âú∞ÂùÄ\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T02:48:58.067468Z",
     "start_time": "2025-11-12T02:48:54.515868Z"
    }
   },
   "cell_type": "code",
   "source": "llm.invoke(\"‰Ω†Â•Ω\")",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='‰Ω†Â•ΩÔºÅÊúâ‰ªÄ‰πàÂèØ‰ª•Â∏ÆÂà∞‰Ω†ÁöÑÂêóÔºüüòä', additional_kwargs={}, response_metadata={'model': 'qwen3:0.6b', 'created_at': '2025-11-12T02:48:58.058410561Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3522255749, 'load_duration': 305408009, 'prompt_eval_count': 11, 'prompt_eval_duration': 22854780, 'eval_count': 116, 'eval_duration': 3094865687, 'model_name': 'qwen3:0.6b', 'model_provider': 'ollama'}, id='lc_run--080827ba-527d-4f50-8d46-aa79f3bbcc7a-0', usage_metadata={'input_tokens': 11, 'output_tokens': 116, 'total_tokens': 127})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T02:48:58.849264Z",
     "start_time": "2025-11-12T02:48:58.097369Z"
    }
   },
   "source": [
    "from langchain_core.prompts import load_prompt\n",
    "# prompt = load_prompt(\"hwchase17/openai-functions-agent\")\n",
    "# prompt.messages\n",
    "from langsmith import Client\n",
    "client = Client(api_key=os.getenv(\"LANGSMITH_API_KEY\"))\n",
    "prompt = client.pull_prompt(\"hwchase17/openai-functions-agent\", include_model=False)\n",
    "prompt.messages"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T02:48:59.239402Z",
     "start_time": "2025-11-12T02:48:58.855348Z"
    }
   },
   "source": [
    "from langchain_classic.agents import create_openai_tools_agent\n",
    "#ËøôÈáåÁöÑtoolsÂèÇÊï∞‰∏ªË¶ÅÊèê‰æõÂ∑•ÂÖ∑ÁöÑÊèèËø∞‰ø°ÊÅØ(Âõ†‰∏∫ÂÜÖÈÉ®Ë¶ÅÂØπ)\n",
    "agent=create_openai_tools_agent(llm,tools,prompt)"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Executor"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T02:48:59.251922Z",
     "start_time": "2025-11-12T02:48:59.245991Z"
    }
   },
   "source": [
    "from langchain_classic.agents import AgentExecutor\n",
    "#ËøôÈáåÁöÑtoolsÂèÇÊï∞‰∏ªË¶ÅÂÖ∑‰ΩìÁöÑÊâßË°åÂáΩÊï∞\n",
    "agent_executor=AgentExecutor(agent=agent,tools=tools,verbose=True)\n",
    "agent_executor"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(verbose=True, agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x73e7ae8c3a60>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x73e7ae8c3a60>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatOllama(model='qwen3:0.6b', base_url='http://localhost:11434'), kwargs={'tools': [{'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'langsmith_search', 'description': 'Search for information about Langsmith. For any questions about LangSmith, youmust use this tool', 'parameters': {'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])\n",
       "| OpenAIToolsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from '/home/chester/gitlab.chesterwang.com/ai_demo_4_interview/RAG/RAG-Level-01/P01-RAG-Projects/.venv/lib/python3.11/site-packages/wikipedia/__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=200)), ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=3, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=4000)), Tool(name='langsmith_search', description='Search for information about Langsmith. For any questions about LangSmith, youmust use this tool', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x73e65186d4e0>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x73e652399650>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x73e6504eed40>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x73e652399650>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T03:34:53.875534Z",
     "start_time": "2025-11-12T03:33:41.708998Z"
    }
   },
   "source": [
    "response=agent_executor.invoke({\"input\":\"What's the paper 1605.08386 about?\"})\n",
    "# ËøôÈáå‰ΩøÁî®deepseek-r1:1.5b ÁöÑÁªìÊûúÊòØÊÄªÊòØ‰∏ç‰ºöË∞ÉÁî®Áõ∏ÂÖ≥Â∑•ÂÖ∑„ÄÇ"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3m\n",
      "Invoking: `arxiv` with `{'query': '1605.08386'}`\n",
      "\n",
      "\n",
      "\u001B[0m\u001B[33;1m\u001B[1;3mPublished: 2016-05-27\n",
      "Title: Heat-bath random walks with Markov bases\n",
      "Authors: Caprice Stanley, Tobias Windisch\n",
      "Summary: Graphs on lattice points are studied whose edges come from a finite set of allowed moves of arbitrary length. We show that the diameter of these graphs on fibers of a fixed integer matrix can be bounded from above by a constant. We then study the mixing behaviour of heat-bath random walks on these graphs. We also state explicit conditions on the set of moves so that the heat-bath random walk, a generalization of the Glauber dynamics, is an expander in fixed dimension.\u001B[0m\u001B[32;1m\u001B[1;3mThe paper titled **\"Heat-bath random walks with Markov bases\"** was published on **2016-05-27**.  \n",
      "**Authors**: Caprice Stanley, Tobias Windisch.  \n",
      "**Summary**:  \n",
      "Graphs on lattice points with edges derived from finite sets of allowed moves of arbitrary length are studied. The paper shows that the **diameter** of these graphs on fibers of a fixed integer matrix can be bounded from above by a constant. It also investigates the **mixing behavior** of heat-bath random walks on these graphs. Additionally, the paper states that **explicit conditions** on the set of moves ensure the heat-bath random walk (a generalization of Glauber dynamics) behaves as an **expander** in fixed dimension.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T03:35:00.657962Z",
     "start_time": "2025-11-12T03:35:00.654690Z"
    }
   },
   "source": [
    "print(response)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': \"What's the paper 1605.08386 about?\", 'output': 'The paper titled **\"Heat-bath random walks with Markov bases\"** was published on **2016-05-27**.  \\n**Authors**: Caprice Stanley, Tobias Windisch.  \\n**Summary**:  \\nGraphs on lattice points with edges derived from finite sets of allowed moves of arbitrary length are studied. The paper shows that the **diameter** of these graphs on fibers of a fixed integer matrix can be bounded from above by a constant. It also investigates the **mixing behavior** of heat-bath random walks on these graphs. Additionally, the paper states that **explicit conditions** on the set of moves ensure the heat-bath random walk (a generalization of Glauber dynamics) behaves as an **expander** in fixed dimension.'}\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T02:52:51.245950Z",
     "start_time": "2025-11-12T02:52:43.636020Z"
    }
   },
   "source": [
    "response=agent_executor.invoke({\"input\":\"introduce the GPU to me?\"})\n",
    "# ËøôÈáå‰ΩøÁî®deepseek-r1:1.5b ÁöÑÁªìÊûúÊòØÊÄªÊòØ‰∏ç‰ºöË∞ÉÁî®Áõ∏ÂÖ≥Â∑•ÂÖ∑„ÄÇ"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3mA GPU (Graphics Processing Unit) is a parallel processor designed to handle graphics and compute tasks efficiently. It's used in computers for tasks like gaming, video editing, and 3D modeling. Unlike CPUs, which are slower, GPUs can process thousands of threads at once, making them much faster for tasks that require visual processing. Examples include NVIDIA's GPUs and AMD's GPUs. They‚Äôre optimized for parallel computations, making them essential in modern computing.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T02:50:23.526597976Z",
     "start_time": "2025-11-08T12:59:48.232350Z"
    }
   },
   "source": "print(response)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'introduce the GPU to me?', 'output': \"A GPU (Graphics Processing Unit) is a parallel processor used in computers to accelerate data processing tasks. It's responsible for rendering graphics, such as in games, video editing, or machine learning, by handling complex calculations that a CPU would take time to process. Unlike a CPU, which is slower, GPUs can handle multiple tasks simultaneously, making them ideal for applications that require significant computational power.\"}\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
