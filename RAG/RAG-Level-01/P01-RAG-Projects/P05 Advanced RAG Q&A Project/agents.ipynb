{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Advanced RAG Q&A Project With Multiple Data Sources With Langchain"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T10:47:02.984538Z",
     "start_time": "2025-11-08T10:47:02.241426Z"
    }
   },
   "source": [
    "from langchain_community.tools import WikipediaQueryRun \n",
    "from langchain_community.utilities import WikipediaAPIWrapper"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API wrapper\n",
    "- this is basically use to query answer from wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T10:47:25.272089Z",
     "start_time": "2025-11-08T10:47:24.922982Z"
    }
   },
   "source": [
    "api_wrapper=WikipediaAPIWrapper(top_k_results=1,doc_content_chars_max=200)\n",
    "wiki=WikipediaQueryRun(api_wrapper=api_wrapper)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T10:47:27.173951Z",
     "start_time": "2025-11-08T10:47:27.163231Z"
    }
   },
   "source": [
    "wiki.name"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T10:47:49.526824Z",
     "start_time": "2025-11-08T10:47:49.523020Z"
    }
   },
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T11:17:00.989096Z",
     "start_time": "2025-11-08T11:17:00.972046Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_BASE\"] = os.getenv(\"OPENAI_API_BASE\")\n",
    "os.environ['OPENAI_API_KEY']=os.getenv('OPENAI_API_KEY')"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T10:49:20.190486Z",
     "start_time": "2025-11-08T10:47:54.161461Z"
    }
   },
   "source": [
    "loader=WebBaseLoader('https://docs.smith.langchain.com/')\n",
    "docs=loader.load()\n",
    "documents=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200).split_documents(docs)"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T10:49:39.194570Z",
     "start_time": "2025-11-08T10:49:23.602194Z"
    }
   },
   "source": [
    "# 临时增加代理\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# 临时增加代理\n",
    "os.environ['HTTP_PROXY'] = \"http://127.0.0.1:7890\"\n",
    "os.environ['HTTPS_PROXY'] = \"http://127.0.0.1:7890\"\n",
    "\n",
    "model_name = \"BAAI/bge-large-zh-v1.5\"\n",
    "model_kwargs = {'device': 'cpu', \"trust_remote_code\":True}\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "hf_emb_model = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "# 去除增加代理\n",
    "os.environ.pop('HTTP_PROXY')\n",
    "os.environ.pop('HTTPS_PROXY')\n",
    "\n",
    "## creating vector DB\n",
    "vectordb=FAISS.from_documents(documents, hf_emb_model)\n",
    "retriever=vectordb.as_retriever()\n",
    "retriever"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://127.0.0.1:7890'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'http://127.0.0.1:7890'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x7753fcee0710>, search_kwargs={})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T10:58:32.896049Z",
     "start_time": "2025-11-08T10:58:32.891086Z"
    }
   },
   "source": [
    "from langchain_core.tools.retriever import create_retriever_tool\n",
    "retriever_tool=create_retriever_tool(retriever,\"langsmith_search\",\"Search for information about Langsmith. For any questions about LangSmith, youmust use this tool\")"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T10:58:34.036363Z",
     "start_time": "2025-11-08T10:58:34.031806Z"
    }
   },
   "source": [
    "retriever_tool.name"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'langsmith_search'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arxiv Tool"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T10:58:37.623863Z",
     "start_time": "2025-11-08T10:58:37.529652Z"
    }
   },
   "source": [
    "from langchain_community.utilities import ArxivAPIWrapper\n",
    "from langchain_community.tools import ArxivQueryRun\n"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T11:05:17.431499Z",
     "start_time": "2025-11-08T11:05:17.337363Z"
    }
   },
   "source": [
    "arxiv_wrapper=ArxivAPIWrapper(top_k_results=1, doc_content_chars_max=200)\n",
    "arxiv=ArxivQueryRun(arxiv_wrapper=arxiv_wrapper)\n",
    "arxiv.name"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arxiv'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine All Tools"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T11:05:25.661777Z",
     "start_time": "2025-11-08T11:05:25.654880Z"
    }
   },
   "source": [
    "tools=[wiki,arxiv,retriever_tool]"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T11:05:27.555571Z",
     "start_time": "2025-11-08T11:05:27.550289Z"
    }
   },
   "source": [
    "tools"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from '/home/chester/gitlab.chesterwang.com/ai_demo_4_interview/RAG/.venv/lib/python3.11/site-packages/wikipedia/__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=200)),\n",
       " ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=3, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=4000)),\n",
       " Tool(name='langsmith_search', description='Search for information about Langsmith. For any questions about LangSmith, youmust use this tool', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x7753a83a2480>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x7753fcee0710>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x7753a823ad40>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x7753fcee0710>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents\n",
    "- The core idea of agents is to use a language model to choose a sequence of actions to take. In chains, a sequence of actions is hardcoded (in code). In agents, a language model is used as a reasoning engine to determine which actions to take and in which order.\n",
    "[Learn more](https://python.langchain.com/v0.1/docs/modules/agents/)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T11:05:45.540384Z",
     "start_time": "2025-11-08T11:05:45.298906Z"
    }
   },
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "# llm = ChatOpenAI(model=\"kimi-k2-turbo-preview\", temperature=0) # 会遇到httpcore的问题\n",
    "# from langchain_community.llms import Ollama,ChatOllama\n",
    "from langchain_ollama import ChatOllama\n",
    "# llm = Ollama(model=\"deepseek-r1:1.5b\",\n",
    "#     base_url=\"http://localhost:11434\"  # 明确指定 Ollama 服务地址\n",
    "# )\n",
    "llm = ChatOllama(model=\"qwen3:0.6b\",\n",
    "    base_url=\"http://localhost:11434\"  # 明确指定 Ollama 服务地址\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T12:57:57.436281Z",
     "start_time": "2025-11-08T12:57:55.052339Z"
    }
   },
   "source": [
    "from langchain_core.prompts import load_prompt\n",
    "# prompt = load_prompt(\"hwchase17/openai-functions-agent\")\n",
    "# prompt.messages\n",
    "from langsmith import Client\n",
    "client = Client(api_key=os.getenv(\"LANGSMITH_API_KEY\"))\n",
    "prompt = client.pull_prompt(\"hwchase17/openai-functions-agent\", include_model=False)\n",
    "prompt.messages"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T12:57:59.466759Z",
     "start_time": "2025-11-08T12:57:59.382554Z"
    }
   },
   "source": [
    "from langchain_classic.agents import create_openai_tools_agent\n",
    "#这里的tools参数主要提供工具的描述信息(因为内部要对)\n",
    "agent=create_openai_tools_agent(llm,tools,prompt)"
   ],
   "outputs": [],
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Executor"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T12:58:01.349732Z",
     "start_time": "2025-11-08T12:58:01.331368Z"
    }
   },
   "source": [
    "from langchain_classic.agents import AgentExecutor\n",
    "#这里的tools参数主要具体的执行函数\n",
    "agent_executor=AgentExecutor(agent=agent,tools=tools,verbose=True)\n",
    "agent_executor"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(verbose=True, agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x77555d8a6840>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x77555d8a6840>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatOllama(model='qwen3:0.6b', base_url='http://localhost:11434'), kwargs={'tools': [{'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'langsmith_search', 'description': 'Search for information about Langsmith. For any questions about LangSmith, youmust use this tool', 'parameters': {'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])\n",
       "| OpenAIToolsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from '/home/chester/gitlab.chesterwang.com/ai_demo_4_interview/RAG/.venv/lib/python3.11/site-packages/wikipedia/__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=200)), ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=3, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=4000)), Tool(name='langsmith_search', description='Search for information about Langsmith. For any questions about LangSmith, youmust use this tool', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x7753a83a2480>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x7753fcee0710>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x7753a823ad40>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x7753fcee0710>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T12:58:31.154650Z",
     "start_time": "2025-11-08T12:58:02.420971Z"
    }
   },
   "source": [
    "response=agent_executor.invoke({\"input\":\"What's the paper 1605.08386 about?\"})\n",
    "# 这里使用deepseek-r1:1.5b 的结果是总是不会调用相关工具。"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3m\n",
      "Invoking: `arxiv` with `{'query': '1605.08386'}`\n",
      "\n",
      "\n",
      "\u001B[0m\u001B[33;1m\u001B[1;3mPublished: 2016-05-26\n",
      "Title: Heat-bath random walks with Markov bases\n",
      "Authors: Caprice Stanley, Tobias Windisch\n",
      "Summary: Graphs on lattice points are studied whose edges come from a finite set of\n",
      "allowed moves of arbitrary length. We show that the diameter of these graphs on\n",
      "fibers of a fixed integer matrix can be bounded from above by a constant. We\n",
      "then study the mixing behaviour of heat-bath random walks on these graphs. We\n",
      "also state explicit conditions on the set of moves so that the heat-bath random\n",
      "walk, a generalization of the Glauber dynamics, is an expander in fixed\n",
      "dimension.\u001B[0m\u001B[32;1m\u001B[1;3mThe paper titled **\"Heat-bath random walks with Markov bases\"** was published on **2016-05-26**. It explores graphs whose edges correspond to moves on a finite set of allowed steps, specifically studied for their **diameter** and **mixing behavior**. The authors, **Caprice Stanley and Tobias Windisch**, show that the graphs form expander structures with constant bounds on their diameter and analyze how heat-bath random walks behave on such graphs. The work also introduces conditions for the heat-bath dynamics to be an expander in fixed dimensions.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T14:59:37.990363Z",
     "start_time": "2025-11-07T14:59:37.984090Z"
    }
   },
   "source": [
    "print(response)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': \"What's the paper 1605.08386 about?\", 'output': 'The paper with the identifier 1605.08386 is from the ACM Transactions on Algorithms. It is a research paper published by the Association for Computing Machinery (ACM). If you have more details or context about the paper, I can provide further information.'}\n"
     ]
    }
   ],
   "execution_count": 84
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T12:59:12.806259Z",
     "start_time": "2025-11-08T12:59:03.649788Z"
    }
   },
   "source": [
    "response=agent_executor.invoke({\"input\":\"introduce the GPU to me?\"})\n",
    "# 这里使用deepseek-r1:1.5b 的结果是总是不会调用相关工具。"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3mA GPU (Graphics Processing Unit) is a parallel processor used in computers to accelerate data processing tasks. It's responsible for rendering graphics, such as in games, video editing, or machine learning, by handling complex calculations that a CPU would take time to process. Unlike a CPU, which is slower, GPUs can handle multiple tasks simultaneously, making them ideal for applications that require significant computational power.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T12:59:48.246075Z",
     "start_time": "2025-11-08T12:59:48.232350Z"
    }
   },
   "source": "print(response)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'introduce the GPU to me?', 'output': \"A GPU (Graphics Processing Unit) is a parallel processor used in computers to accelerate data processing tasks. It's responsible for rendering graphics, such as in games, video editing, or machine learning, by handling complex calculations that a CPU would take time to process. Unlike a CPU, which is slower, GPUs can handle multiple tasks simultaneously, making them ideal for applications that require significant computational power.\"}\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
